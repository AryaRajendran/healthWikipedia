{{Merge from|Perception and production of music|discuss=Talk:Cognitive neuroscience of music#Another merger proposal|date=January 2012}}

<!-- Deleted image removed: [[Image:sensationofmusic.gif|thumb|right|250px|The sensation of music in the human brain]] -->
The '''[[cognitive neuroscience]] of music''' is the scientific study of brain-based mechanisms involved in the cognitive processes underlying [[music]]. These behaviours include music [[listening]], [[Performance|performing]], [[Musical composition|composing]], reading, writing, and ancillary activities. It also is increasingly concerned with the brain basis for [[Aesthetics of music|musical aesthetics]] and musical emotion. Scientists working in this field may have training in cognitive neuroscience, [[neurology]], [[neuroanatomy]], [[psychology]], [[music theory]], [[computer science]], and other allied fields. 

Cognitive neuroscience of music is distinguished from related fields such as [[music psychology]], [[music cognition]] and [[cognitive musicology]] in its reliance on direct observations of the brain, using such techniques as [[functional magnetic resonance imaging]] (fMRI), [[transcranial magnetic stimulation]] (TMS), [[magnetoencephalography]] (MEG), [[electroencephalography]] (EEG), and [[positron emission tomography]] (PET).

== Neurological bases ==

===Pitch===
Successive parts of the [[tonotopy|tonotopically]] organized [[basilar membrane]] in the [[cochlea]] resonate to corresponding [[frequency]] [[Bandwidth (signal processing)|bandwidths]] of incoming sound. The [[hair cell]]s in the cochlea release [[neurotransmitter]] as a result, causing [[action potentials]] down the [[auditory nerve]]. The auditory nerve then leads to several layers of [[synapses]] at numerous [[Nucleus (neuroanatomy)|nuclei]] in the [[Auditory_system#Central_auditory_system|auditory brainstem]]. These nuclei are also tonotopically organized, and the process of achieving this tonotopy after the cochlea is not well understood.<ref>{{cite journal|last1=Kandler|first1=K|last2=Clause|first2=A|last3=Noh|first3=J|title=Tonotopic reorganization of developing auditory brainstem circuits|journal=Nature Neuroscience|year=2009|month=May|volume=12|issue=6|pages=711–717|doi=10.1038/nn.2332|url=http://www.nature.com/neuro/journal/v12/n6/abs/nn.2332.html}}</ref> This tonotopy is in general maintained up to [[primary auditory cortex]] in [[mammals]],<ref>{{cite journal | doi = 10.1016/0013-4694(82)90118-3 | last1 = Arlinger | first1 = S. | last2 = Elberling | first2 = C. | last3 = Bak | first3 = C. | last4 = Kofoed | first4 = B. | last5 = Lebech | first5 = J. | last6 = Saermark | first6 = K. | year = 1982 | title = Cortical magnetic fields evoked by frequency glides of a continuous tone | url = | journal = EEG & Clinical Neurophysiology | volume = 54 | issue = 6| pages = 642–653 }}</ref> however it is often found that cells in primary and non-primary auditory cortex have [[Spatio temporal receptive field|spatio-temporal receptive fields]], rather than being strictly responsive or phase-locking their action potentials to narrow frequency regions.<ref>{{cite journal|last1=Ghazanfar|first1=A|last2=Nicolalis|first2=M|title=The Structure and Function of Dynamic Cortical and Thalamic Receptive Fields|journal=Cerebral Cortex|year=2001|volume=11|issue=3|pages=183–193|doi=10.1093/cercor/11.3.183|url=http://cercor.oxfordjournals.org/content/11/3/183.full}}</ref><ref>{{cite journal|last1=Theunissen|first1=F|last2=David|first2=SV|last3=Singh|first3=NC|last4=Hsu|first4=A|last5=Vinje|first5=WE|last6=Gallant|first6=JL|title=Estimating spatio-temporal receptive ﬁelds of auditory and visual neurons from their responses to natural stimuli|journal=Network: Computation in Neural Systems|year=2001|month=August|volume=12|issue=3|pages=289–316|pmid=11563531|url=http://www.ncbi.nlm.nih.gov/pubmed/11563531}}</ref>

A widely-postulated mechanism for pitch processing in the early central auditory system is the [[Circle map|phase-locking]] and [[Arnold_tongue#Mode_locking|mode-locking]] of action potentials to frequencies in a stimulus. Phase-locking to stimulus frequencies has been shown in the auditory nerve,<ref name="Koppl 1997 3312–3321">{{cite journal|last=Koppl|first=Christine|title=Phase Locking to High Frequencies in the Auditory Nerve and Cochlear Nucleus Magnocellularis of the Barn Owl, Tyto alba|journal=Journal of Neuroscience|year=1997|month=May|volume=17|issue=9|pages=3312–3321|pmid=9096164|url=http://www.jneurosci.org/content/17/9/3312.abstract}}</ref><ref>{{cite journal|last=Dreyer|first=A.|coauthors=Delgutte, B.|title=Phase locking of auditory-nerve fibers to the envelopes of high-frequency sounds: implications for sound localization|journal=Journal of Neurophysiology|year=2006|month=November|volume=96|issue=5|pages=2327–2341|pmid=16807349|url=http://www.ncbi.nlm.nih.gov/pubmed/16807349|doi=10.1152/jn.00326.2006|pmc=2013745}}</ref> the [[cochlear nucleus]],<ref name="Koppl 1997 3312–3321"/><ref>{{cite journal|last=Laudanski|first=J.|coauthors=Coombes, S., Palmer, A., Sumner, C.|title=Mode-Locked Spike Trains in Responses of Ventral Cochlear Nucleus Chopper and Onset Neurons to Periodic Stimuli|journal=Journal of Neurophysiology|year=2010|volume=103|issue=3|pages=1226–1237|doi=10.1152/jn.00070.2009|pmid=20042702}}</ref> the [[inferior colliculus]],<ref>{{cite journal|last=Liu|first=L.F.|coauthors=Palmer, A.R., Wallace, M.N.|title=Phase-Locked Responses to Pure Tones in the Inferior Colliculus|journal=Journal of Neurophysiology|year=2006|month=March|volume=95|issue=3|pages=1926–1935|doi=10.1152/jn.00497.2005|pmid=16339005}}</ref> and the [[Medial geniculate nucleus|auditory thalamus]].<ref>{{cite journal|last=Wallace|first=M.N.|coauthors=Anderson, L.A., Palmer, A.R.|title=Phase-Locked Responses to Pure Tones in the Auditory Thalamus|journal=Journal of Neurophysiology|year=2007|month=October|volume=98|issue=4|pages=1941–1952|doi=10.1152/jn.00697.2007|pmid=17699690}}</ref> By phase- and mode-locking in this way, the auditory brainstem is known to preserve a good deal of the temporal and [[Low-pass filter|low-passed]] frequency information from the original sound; this is evident by measuring the [[auditory brainstem response]] using [[EEG]].<ref>{{cite journal|last=Skoe|first=E.|coauthors=Kraus, N.|title=Auditory brainstem response to complex sounds: a tutorial|journal=Ear and Hearing|year=2010|month=June|volume=31|issue=3|pages=302–324|doi=10.1097/AUD.0b013e3181cdb272|pmid=20084007|pmc=2868335}}</ref> This temporal preservation is one way to argue directly for the [[Temporal theory (hearing)|temporal theory]] of [[Pitch_(music)#Perception_of_pitch|pitch perception]], and to argue [[Argument from ignorance|indirectly]] against the [[Place theory (hearing)|place theory]] of pitch perception.

=== Melody processing in the secondary auditory cortex ===

Studies suggest that individuals are capable of automatically detecting a difference or anomaly in a [[melody]] such as an out of tune [[pitch (music)|pitch]] which does not fit with their previous music experience. This automatic processing occurs in the secondary auditory cortex. Brattico, Tervaniemi, Naatanen, and Peretz (2006) performed one such study to determine if the detection of tones that do not fit an individual's expectations can occur automatically.<ref name="Brattico">{{cite journal | doi = 10.1016/j.brainres.2006.08.023 | last1 = Brattico | first1 = E. | last2 = Tervaniemi | first2 = M. | last3 = Naatanen | first3 = R. | last4 = Peretz | first4 = I. | year = 2006 | title = Musical scale properties are automatically processed in the human auditory cortex | url = | journal = Brain Research | volume = 1117 | issue = 1| pages = 162–174 | pmid = 16963000 }}</ref>  They recorded [[event-related potential]]s (ERPs) in nonmusicians as they were presented unfamiliar melodies with either an out of tune pitch or an out of key pitch while participants were either distracted from the sounds or attending to the melody. Both conditions revealed an early frontal negativity independent of where attention was directed. This negativity originated in the auditory cortex, more precisely in the supratemporal lobe (which corresponds with the secondary auditory cortex) with greater activity from the right hemisphere. The negativity response was larger for pitch that was out of tune than that which was out of key. Ratings of musical incongruity were higher for out of tune pitch melodies than for out of key pitch.  In the focused attention condition, out of key and out of tune pitches produced late parietal positivity. The findings of Brattico et al. (2006) suggest that there is automatic and rapid processing of melodic properties in the secondary auditory cortex.<ref name="Brattico"/> The findings that pitch incongruities were detected automatically, even in processing unfamiliar melodies, suggests that there is an automatic comparison of incoming information with long term knowledge of musical scale properties, such as culturally influenced rules of musical properties (common chord progressions, scale patterns, etc.) and individual expectations of how the melody should proceed.

=== Role of right auditory cortex in fine pitch resolution ===

[[File:Brodmann 41 42.png|right|250px|thumb|The [[primary auditory cortex]] is one of the main areas associated with superior pitch resolution.]]

The right secondary auditory cortex has finer pitch resolution than the left. Hyde, Peretz and Zatorre (2008) used functional magnetic resonance imaging (fMRI) in their study to test the involvement of right and left auditory cortical regions in frequency processing of melodic sequences.<ref>{{cite journal | doi = 10.1016/j.neuropsychologia.2007.09.004 | last1 = Hyde | first1 = K. L | last2 = Peretz | first2 = I. | last3 = Zatorre | first3 = R. J. | year = 2008 | title = Evidence for the role of the right auditory cortex in fine pitch resolution | url = | journal = Neuropsychologia | volume = 46 | issue = 2| pages = 632–639 | pmid = 17959204 }}</ref> As well as finding superior pitch resolution in the right secondary auditory cortex, specific areas found to be involved were the [[planum temporale]] (PT) in the secondary auditory cortex, and the [[primary auditory cortex]] in the medial section of Heschl's gyrus (HG). 

Many neuroimaging studies have found evidence of the importance of right secondary auditory regions in aspects of musical pitch processing, such as melody.<ref>{{cite journal | doi = 10.1016/S0896-6273(02)01060-7 | last1 = Patterson | first1 = R. D. | last2 = Uppenkamp | first2 = S. | last3 = Johnsrude | first3 = I. S. | author3-link = Ingrid Johnsrude | last4 = Griffiths | first4 = T. D. | year = 2002 | title = The processing of temporal pitch and melody information in auditory cortex | url = | journal = Neuron | volume = 36 | issue = 4| pages = 767–776 | pmid = 12441063 }}</ref> Many of these studies such as one by Patterson, Uppenkamp, Johnsrude and Griffiths (2002) also find evidence of a hierarchy of pitch processing. Patterson et al. (2002) used spectrally matched sounds which produced: no pitch, fixed pitch or melody in an fMRI study and found that all conditions activated HG and PT. Sounds with pitch activated more of these regions than sounds without. When a melody was produced activation spread to the [[superior temporal gyrus]] (STG) and planum polare (PP). These results support the existence of a pitch processing hierarchy.

===Rhythm===
The belt and parabelt areas of the right hemisphere are involved in processing [[rhythm]]. When individuals are preparing to tap out a rhythm of regular intervals (1:2 or 1:3) the left [[frontal cortex]], left [[parietal cortex]], and right [[cerebellum]] are all activated.  With more difficult rhythms such as a 1:2.5, more areas in the cerebral cortex and cerebellum are involved.<ref name="Tramo">{{cite journal | last1 = Tramo | first1 = MJ. | author-separator =, | author-name-separator= | year = 2001 | title = Biology and music. Music of the hemispheres | url = | journal = Science | volume = 291 | issue = 5501| pages = 54–6 | pmid = 11192009 |doi=10.1126/science.10.1126/SCIENCE.1056899 }}</ref> [[EEG]] recordings have also shown a relationship between brain electrical activity and rhythm perception. Snyder and Large (2005)<ref>{{cite journal|last1=Snyder|first1=J|last2=Large|first2=E|title=Gamma-band activity reflects the metric structure of rhythmic tone sequences|journal=Cognitive Brain Research|year=2005|month=February|volume=24|issue=1|pages=117–126|doi=10.1016/j.cogbrainres.2004.12.014|url=http://www.sciencedirect.com/science/article/pii/S0926641005000054}}</ref> performed a study examining rhythm perception in human subjects, finding that activity in the [[gamma wave|gamma band]] (20 – 60&nbsp;Hz) corresponds to the [[Beat (music)|beats]] in a simple rhythm. Two types of gamma activity were found by Snyder & Large: induced gamma activity, and [[Evoked_potential#Auditory_evoked_potential|evoked]] gamma activity. Evoked gamma activity was found after the onset of each tone in the rhythm; this activity was found to be phase-locked (peaks and troughs were directly related to the exact onset of the tone) and did not appear when a gap (missed beat) was present in the rhythm. Induced gamma activity, which was not found to be phase-locked, was also found to correspond with each beat. However, induced gamma activity did not subside when a gap was present in the rhythm, indicating that induced gamma activity may possibly serve as a sort of internal metronome independent of auditory input.

===Tonality===
[[Tonality]] describes the relationships between the elements of melody and [[harmony]] - tones, [[Interval (music)|intervals]], [[Chord (music)|chords]], and [[Scale (music)|scales]]. These relationships are often characterised as hierarchical, such that one of the elements dominates or attracts another. They occur both within and between every type of element, creating a rich and time-varying percept between tones and their melodic, harmonic, and [[Chromatic scale|chromatic]] contexts. In one conventional sense, tonality refers to just the [[Major scale|major]] and [[Minor scale|minor]] scale types - examples of scales whose elements are capable of maintaining a consistent set of functional relationships. The most important functional relationship is that of the [[Tonic (music)|tonic]] note and the tonic chord with the rest of the scale. The tonic is the element which tends to assert its dominance and attraction over all others, and it functions as the ultimate point of attraction, rest and resolution for the scale.<ref>{{cite book|last=Krumhansl|first=Carol|title=Cognitive Foundations of Musical PItch|year=1990|publisher=Oxford University Press|location=New York, NY|isbn=978-0195148367}}</ref> 

The right auditory cortex is primarily involved in perceiving  pitch, and parts of harmony, melody and rhythm.<ref name="Tramo"/> One study by Petr Janata found that there are tonality-sensitive areas in the [[medial prefrontal cortex]], the [[cerebellum]], the [[Superior temporal sulcus|superior temporal sulci]] of both hemispheres and the [[Superior temporal gyrus|superior temporal gyri]] (which has a skew towards the right hemisphere).<ref>{{cite journal | doi = 10.1126/science.1076262 | last1 = Janata | first1 = P | last2 = Birk | first2 = J | last3 = Van Horn | first3 = J | last4 = Leman | first4 = M | last5 = Tillmann | first5 = B | last6 = Bharucha | first6 = J. | author-separator =, | author-name-separator= | year = 2002 | title = The cortical topography of tonal structures underlying Western music | url = | journal = Science | volume = 298 | issue = 5601| pages = 2167–70 | pmid = 12481131 }}</ref>

== Music and language ==

Certain aspects of [[language]] and melody have been shown to be processed in near identical functional brain areas.  Brown, Martinez and Parsons (2006) examined the neurological structural similarities between music and language.<ref name="Brown">{{cite journal | doi = 10.1111/j.1460-9568.2006.04785.x | last1 = Brown | first1 = S. | last2 = Martinez | first2 = M.J. | last3 = Parsons | first3 = L.M. | year = 2006 | title = Music and language side by side in the brain: a PET study of the generation of melodies and sentences | url = | journal = European Journal of Neuroscience | volume = 23 | issue = 10| pages = 2791–2803 | pmid = 16817882 }}</ref>  Utilizing positron emission tomography (PET), the findings showed that both linguistic and melodic phrases produced activation in almost identical functional brain areas.  These areas included the [[primary motor cortex]], [[supplementary motor area]], [[Broca's area]], anterior insula, primary and secondary auditory cortices, temporal pole, [[basal ganglia]], ventral [[thalamus]] and posterior [[cerebellum]].  Differences were found in lateralization tendencies as language tasks favoured the left hemisphere, but the majority of activations were bilateral which produced significant overlap across modalities.<ref name="Brown"/>

Syntactical information mechanisms in both music and language have been shown to be processed similarly in the brain.  Jentschke, Koelsch, Sallat and Friederici (2008) conducted a study investigating the processing of music in children with [[Speech and language pathology in school settings#Specific language impairment|specific language impairments]] (SLI).<ref name="Jentschke">{{cite journal | doi = 10.1162/jocn.2008.20135 | last1 = Jentschke | first1 = S. | last2 = Koelsch | first2 = S. | last3 = Sallat | first3 = S. | last4 = Friederici | first4 = A.D. | year = 2008 | title = Children with specific language impairment also show impairment of music-syntactic processing | url = | journal = Journal of Cognitive Neuroscience | volume = 20 | issue = 11| pages = 1940–1951 | pmid = 18416683 }}</ref>  Children with typical language development (TLD) showed ERP patterns different than that of children with SLI which reflected their challenges to process music-syntactic regularities.  Strong correlations between the ERAN (''Early Right Anterior Negativity''—a specific ERP measure) amplitude and linguistic and musical abilities provide additional evidence for the relationship of syntactical processing in music and language.<ref name="Jentschke"/>

However, production of melody and production of speech may be subserved by different neural networks.  Stewart, Walsh, Frith and Rothwell (2001) studied the differences between speech production and song production using transcranial magnetic stimulation (TMS).<ref name="Stewart">{{cite journal | doi = 10.1111/j.1749-6632.2001.tb05762.x | last1 = Stewart | first1 = L. | last2 = Walsh | first2 = V. | last3 = Frith | first3 = U. | last4 = Rothwell | first4 = J. | year = 2001 | title = Transcranial magnetic stimulation produces speech arrest but not song arrest | url = | journal = Annals New York Academy of Sciences | volume = 930 | issue = | pages = 433–35 }}</ref>  Stewart et al. found that TMS applied to the left [[frontal lobe]] disturbs speech but not melody supporting the idea that they are subserved by different areas of the brain.  The authors suggest that a reason for the difference is that speech generation can be localized well but the underlying mechanisms of melodic production cannot.  Alternatively, it was also suggested that speech production may be less robust than melodic production and thus more susceptible to interference.<ref name="Stewart"/>

Language processing is a function more of the left side of the brain than the right side, particularly [[Broca's Area]] and [[Wernicke's area]], though the roles played by the two sides of the brain in processing different aspects of language are still unclear. Music is also processed by both the left and the right sides of the brain.<ref name="mb1">{{cite journal | doi=10.1006/nimg.2002.1154 | author=Koelsch, S., Gunter, T., Cramon, D., Zysset, S., Lohmann, G. & Friederici, A. | title=Bach Speaks: A Cortical Language-Network Serves the Processing of Music | journal=NeuroImage|volume=17 | issue=2|pages=956–966|year=2002 | pmid=12377169}}</ref><ref name="mb2">{{cite journal | doi=10.1111/j.1460-9568.2006.04785.x | author=Brown, S., Martinez, M. & Parsons, L.|title=Music and language side by side in the brain: a PET study of the generation of melodies and sentences|journal=European Journal of Neuroscience|volume=23 | issue=10|pages=2791–2803|year=2006 | pmid=16817882}}</ref> Recent evidence further suggest shared processing between language and music at the conceptual level.<ref name=Daltrozzo09>{{cite journal | author = Daltrozzo J., Schön D. | year = 2009 | title = Conceptual processing in music as revealed by N400 effects on words and musical targets | url = http://daltrozzo.net78.net/papers/Daltrozzo_Schon_2009a.pdf | format = PDF | journal = Journal of Cognitive Neuroscience | volume = 21 | issue = 10| pages = 1882–1892 }}</ref> It has also been found that, among music conservatory students, the prevalence of absolute pitch is much higher for speakers of tone language, even controlling for ethnic background, showing that language influences how musical tones are perceived.<ref name="phil-43">{{cite journal | author=Deutsch, D., Henthorn, T., Marvin, E., & Xu H-S | title=Absolute pitch among American and Chinese conservatory students: Prevalence differences, and evidence for a speech-related critical period | journal=Journal of the Acoustical Society of America | volume=119 | issue=2 | pages=719–722 | year=2006 | doi=10.1121/1.2151799 | pmid=16521731}} [http://philomel.com/pdf/JASA-2006_119_719-722.pdf PDF Document]</ref><ref name="phil-388">{{cite journal | author=Deutsch, D., Dooley, K., Henthorn, T. and Head, B. | title=Absolute pitch among students in an American music conservatory: Association with tone language fluency | journal=Journal of the Acoustical Society of America | volume=125 | issue=4 | pages=2398–2403 | year=2009 | pmid=19354413 | doi=10.1121/1.3081389 }} [http://scitation.aip.org/vsearch/servlet/VerityServlet?KEY=ASADL&smode=strresults&sort=rel&maxdisp=25&threshold=0&pjournals=ARLOFJ%2CJASMAN%2CNOCOAN%2CSOUCAU%2CPMARCW%2CATCODK%2CASASTR&possible1=Absolute+pitch+among+students+in+an+American+music+conservatory&possible1zone=article&OUTLOG=NO&viewabs=JASMAN&key=DISPLAY&docID=2&page=0&chapter=0 Weblink] [http://philomel.com/pdf/JASA-2009_125_2398-2403.pdf PDF Document]
</ref>

== Musician vs. non-musician processing ==

[[File:Player piano keyboard.jpg|right|thumb|Professional piano players show less cortical activation for complex finger movement tasks due to structural differences in the brain.]]

=== Differences ===

Brain structure within musicians and non-musicians is distinctly different.  Gaser and Schlaug (2003) compared brain structures of professional musicians with non-musicians and discovered [[Grey matter|gray matter]] volume differences in motor, auditory and visual-spatial brain regions.<ref>{{cite journal | last1 = Gaser | first1 = C. | last2 = Schlaug | first2 = G. | year = 2003 | title = Brain structures differ between musicians and non-musicians | url = | journal = The Journal of Neuroscience | volume = 23 | issue = 27| pages = 9240–9245 | pmid = 14534258 }}</ref>  Specifically, positive correlations were discovered between musician status (professional, amateur and non-musician) and gray matter volume in the primary motor and [[Somatosensory system|somatosensory areas]], [[Premotor cortex|premotor areas]], anterior superior parietal areas and in the inferior temporal gyrus bilaterally.  This strong association between musician status and gray matter differences supports the notion that musicians' brains show use-dependent structural changes.<ref name="ReferenceA">{{cite journal | doi = 10.3389/fpsyg.2011.00393 | last1 = Croom | first1 = A.M. | year = 2012 | title = Music, neuroscience, and the psychology of wellbeing: a précis | url = | journal = Frontiers in Theoretical and Philosophical Psychology | volume = 2 | issue = 393| pages = 1–15 }}</ref> Due to the distinct differences in several brain regions, it is unlikely that these differences are innate but rather due to the long-term acquisition and repetitive rehearsal of musical skills.

Brains of musicians also show functional differences from those of non-musicians.  Krings, Topper, Foltys, Erberich, Sparing, Willmes and Thron (2000) utilized fMRI to study brain area involvement of professional piano players and a control group while performing complex finger movements.<ref>{{cite journal | doi = 10.1016/S0304-3940(99)00930-1 | last1 = Krings | first1 = T. | last2 = Topper | first2 = R. | last3 = Foltys | first3 = H. | last4 = Erberich | first4 = S. | last5 = Sparing | first5 = R. | last6 = Willmes | first6 = K. | last7 = Thron | first7 = A. | year = 1999 | title = Cortical activation patterns during complex motor tasks in piano players and control subjects. A functional magnetic resonance imaging study | url = | journal = Neuroscience Letters | volume = 278 | issue = 3| pages = 189–193 | pmid = 10653025 }}</ref>  Krings et al. found that the professional piano players showed lower levels of cortical activation in motor areas of the brain.  It was concluded that a lesser amount of neurons needed to be activated for the piano players due to long-term motor practice which results in the different cortical activation patterns.  Koeneke, Lutz, Wustenberg and Jancke (2004) reported similar findings in keyboard players.<ref>{{cite journal | last1 = Koeneke | first1 = S. | last2 = Lutz | first2 = K. | last3 = Wustenberg | first3 = T. | last4 = Jancke | first4 = L. | year = 2004 | title = Long-term training affects cerebellar processing in skilled keyboard players | url = | journal = NeuroReport | volume = 15 | issue = 8| pages = 1279–1282 | pmid = 15167549 | doi=10.1097/01.wnr.0000127463.10147.e7}}</ref>  Skilled keyboard players and a control group performed complex tasks involving unimanual and bimanual finger movements.  During task conditions, strong hemodynamic responses in the cerebellum were shown by both non-musicians and keyboard players, but non-musicians showed the stronger response.  This finding indicates that different cortical activation patterns emerge from long-term motor practice. This evidence supports previous data showing that musicians require fewer neurons to perform the same movements.

Musicians have been shown to have significantly more developed left planum temporales, and have also shown to have a greater word memory (Chan et al.). Chan's study controlled for age, grade point average and years of education and found that when given a 16 word memory test, the musicians averaged one to two more words above their non musical counterparts.

=== Similarities ===

Studies have shown that the human brain has an implicit musical ability.<ref name="KoelschGunter">{{cite journal | doi = 10.1162/089892900562183 | last1 = Koelsch | first1 = S. | last2 = Gunter | first2 = T. | last3 = Friederici | first3 = A.D. | last4 = Schoger | first4 = E. | year = 2000 | title = Brain indices of music processing: "nonmusicians" are musical | url = | journal = Journal of Cognitive Neuroscience | volume = 12 | issue = 3| pages = 520–541 | pmid = 10931776 }}</ref><ref name="KoelschSchroger">{{cite journal | doi = 10.1111/1469-8986.3910038 | last1 = Koelsch | first1 = S. | last2 = Schroger | first2 = E. | last3 = Gunter | first3 = T. | year = 2002 | title = Music matters: preattentive musicality of the human brain | url = | journal = Psychophysiology | volume = 39 | issue = 1| pages = 38–48 | pmid = 12206294 }}</ref>  Koelsch, Gunter, Friederici and Schoger (2000) investigated the influence of preceding musical context, task relevance of unexpected [[Chord (music)|chord]]s and the degree of probability of violation on music processing in both musicians and non-musicians.<ref name="KoelschGunter"/>  Findings showed that the human brain unintentionally extrapolates expectations about impending auditory input.  Even in non-musicians, the extrapolated expectations are consistent with music theory.  The ability to process information musically supports the idea of an implicit musical ability in the human brain.  In a follow-up study, Koelsch, Schroger, and Gunter (2002) investigated whether ERAN and N5 could be evoked preattentively in non-musicians.<ref name="KoelschSchroger"/>  Findings showed that both ERAN and N5 can be elicited even in a situation where the musical stimulus is ignored by the listener indicating that there is a highly differentiated preattentive musicality in the human brain.

== Gender differences ==

Minor neurological differences with regard to hemispheric processing exist between brains of males and females.  Koelsch, Maess, Grossmann and Friederici (2003) investigated music processing through EEG and ERPs and discovered gender differences.<ref>{{cite journal | doi = 10.1097/00001756-200304150-00010 | last1 = Koelsch | first1 = S. | last2 = Maess | first2 = B. | last3 = Grossmann | first3 = T. | last4 = Friederici | first4 = A.D. | year = 2003 | title = Electric brain responses reveal gender differences in music processing | url = | journal = NeuroReport | volume = 14 | issue = 5| pages = 709–713 | pmid = 12692468 }}</ref>  Findings showed that females process music information bilaterally and males process music with a right-hemispheric predominance.  However, the early negativity of males was also present over the left hemisphere.  This indicates that males do not exclusively utilize the right hemisphere for musical information processing.  In a follow-up study, Koelsch, Grossman, Gunter, Hahne, Schroger and Friederici (2003)  found that boys show lateralization of the early anterior negativity in the left hemisphere but found a bilateral effect in girls.<ref>{{cite journal | doi = 10.1162/jocn.2003.15.5.683 | last1 = Koelsch | first1 = S. | last2 = Grossmann | first2 = T. | last3 = Gunter | first3 = T.C. | last4 = Hahne | first4 = A. | last5 = Schroger | first5 = E. | last6 = Friederici | first6 = A.D. | year = 2003 | title = Children processing music: electric brain responses reveal musical competence and gender differences | url = | journal = Journal of Cognitive Neuroscience | volume = 15 | issue = 5| pages = 683–693 | pmid = 12965042 }}</ref>  This indicates a developmental effect as early negativity is lateralized in the right hemisphere in men and in the left hemisphere in boys.

== Handedness differences ==

It has been found that subjects who are lefthanded, particularly those who are also ambidextrous, perform better than righthanders on short term memory for the pitch.<ref name="phil-4">{{cite journal | doi=10.1126/science.622558 | author=Deutsch, D. | title=Pitch memory: An advantage for the lefthanded. | journal=Science | volume=199 | issue=4328 | pages=559–560 | year=1978 | pmid=622558 }} [http://philomel.com/pdf/Science-1978_199_559-560.pdf PDF Document]</ref><ref name="phil-25">{{cite journal | author=Deutsch, D. | title=Handedness and Memory for Tonal Pitch.  In J. Herron (Ed.) | journal=Neuropsychology of Lefthandedness | volume= | pages=263–271 | year=1980 }} [http://philomel.com/pdf/Ch-Handedness-1980.pdf PDF Document]</ref>
It was hypothesized that this handedness advantage is due to the fact that lefthanders have more duplication of storage in the two hemispheres than do righthanders. Other work has shown that there are pronounced differences between righthanders and lefthanders (on a statistical basis) in how musical patterns are perceived, when sounds come from different regions of space.  This has been found, for example, in the [[Octave illusion]] <ref name="phil-85">{{cite journal | author=Deutsch, D. | title=An auditory illusion | journal=Nature | volume=251 | issue=5473 | pages=307–309 | year=1974 | pmid=4427654 | doi=10.1038/251307a0 }} [http://www.nature.com/nature/journal/v251/n5473/abs/251307a0.html Weblink] [http://philomel.com/pdf/Nature-1974_251_307-309.pdf PDF Document]
</ref><ref name="phil-2">{{cite journal | author=Deutsch, D. | title=The octave illusion in relation to handedness and familial handedness background. | journal=Neuropsychologia | volume=21 | issue=3 | pages=289–293 | year=1983 | pmid=6877583 | doi=10.1016/0028-3932(83)90047-7}} [http://philomel.com/pdf/Neuropsych-1983_21_289-293.pdf PDF Document]</ref> and the [[Scale illusion]].<ref name="phil-6">{{cite journal | doi=10.1121/1.380573 | author=Deutsch, D. | title=Two-channel listening to musical scales
 | journal=Journal of the Acoustical Society of America | volume=57 | pages=1156–1160 | year=1975 | pmid=1127169 | issue=5}} [http://scitation.aip.org/vsearch/servlet/VerityServlet?KEY=ASADL&smode=strresults&sort=chron&maxdisp=25&threshold=0&pjournals=journals&pjournals=JASMAN&pjournals=ARLOFJ&pjournals=NOCOAN&pjournals=SOUCAU&possible1=Two-channel%20listening%20to%20musical%20scales.%20%0D%0A&possible1zone=title&OUTLOG=NO&viewabs=JASMAN&key=DISPLAY&docID=1&page=1&chapter=0 Weblink] [http://philomel.com/pdf/JASA-1975_57_1156-1160.pdf PDF Document]</ref><ref name="phil-22">{{cite journal | author=Deutsch, D. | title=Grouping mechanisms in music. In D. Deutsch (Ed.) | journal=The psychology of music, 2nd Edition | volume= | pages=299–348 | year=1999 }} [http://philomel.com/pdf/PsychMus_Ch9.pdf PDF Document]</ref>

==Musical imagery==

Musical imagery refers to the experience of replaying music by imagining it inside the head.<ref>{{cite journal | doi = 10.1111/j.1749-6632.2001.tb05733.x | last1 = Halpern | first1 = A.R | year = 2001 | title = Cerebral substrates of musical imagery | url = | journal = Annals New York Academy of Sciences | volume = 930 | issue = | pages = 179–192 }}</ref>  Musicians show a superior ability for musical imagery due to intense musical training.<ref>{{cite journal | doi = 10.1111/j.1460-9568.2008.06515.x | last1 = Herholz | first1 = S.C. | last2 = Lappe | first2 = C. | last3 = Knief | first3 = A. | last4 = Pantev | first4 = C. | year = 2008 | title = Neural basis of music imagery and the effect of musical expertise | url = | journal = European Journal of Neuroscience | volume = 28 | issue = 11| pages = 2352–2360 | pmid = 19046375 }}</ref>  Herholz, Lappe, Knief and Pantev (2008) investigated the differences in neural processing of a musical imagery task in musicians and non-musicians.  Utilizing magnetoencephalography (MEG), Herholz et al. examined differences in the processing of a musical imagery task with familiar melodies in musicians and non-musicians.  Specifically, the study examined whether the [[mismatch negativity]] (MMN) can be based solely on imagery of sounds.  The task involved participants listening to the beginning of a melody, continuation of the melody in his/her head and finally hearing a correct/incorrect tone as further continuation of the melody.  The imagery of these melodies was strong enough to obtain an early preattentive brain response to unanticipated violations of the imagined melodies in the musicians.  These results indicate similar neural correlates are relied upon for trained musicians imagery and perception.  Additionally, the findings suggest that modification of the imagery mismatch negativity (iMMN) through intense musical training results in achievement of a superior ability for imagery and preattentive processing of music.

Perceptual musical processes and musical imagery may share a neural substrate in the brain.  A PET study conducted by Zatorre, Halpern, Perry, Meyer and Evans (1996) investigated [[cerebral blood flow]] (CBF) changes related to auditory imagery and perceptual tasks.<ref>{{cite journal | doi = 10.1162/jocn.1996.8.1.29 | last1 = Zatorre | first1 = R.J. | last2 = Halpern | first2 = A.R. | last3 = Perry | first3 = D.W. | last4 = Meyer | first4 = E. | last5 = Evans | first5 = A.C. | year = 1996 | title = Hearing in the mind's ear: A PET investigation of musical imagery and perception | url = | journal = Journal of Cognitive Neuroscience | volume = 8 | issue = 1| pages = 29–46 }}</ref>  These tasks examined the involvement of particular anatomical regions as well as functional commonalities between perceptual processes and imagery.  Similar patterns of CBF changes provided evidence supporting the notion that imagery processes share a substantial neural substrate with related perceptual processes.  Bilateral neural activity in the secondary auditory cortex was associated with both perceiving and imagining songs.  This implies that within the secondary auditory cortex, processes underlie the phenomenological impression of imagined sounds.  The [[supplementary motor area]] (SMA) was active in both imagery and perceptual tasks suggesting covert vocalization as an element of musical imagery.  CBF increases in the inferior frontal polar cortex and right thalamus suggest that these regions may be related to retrieval and/or generation of auditory information from memory.

== Absolute pitch ==

[[File:A C D notes.svg|right|150px|thumb|Musicians possessing perfect pitch can identify the pitch of musical tones without external reference.]]

[[Absolute pitch]] (AP) is defined as the ability to identify the pitch of a musical tone or to produce a musical tone at a given pitch without the use of an external reference pitch.<ref>{{cite journal | doi = 10.1037/0033-2909.113.2.345 | last1 = Takeuchi | first1 = A.H. | last2 = Hulse | first2 = S.H. | year = 1993 | title = Absolute pitch | url = | journal = Psychological Bulletin | volume = 113 | issue = 2| pages = 345–361 | pmid = 8451339 }}</ref>  Neuroscientific research has not discovered a distinct activation pattern common for possessors of AP.  Zatorre, Perry, Beckett, Westbury and Evans (1998) examined the neural foundations of AP using functional and structural brain imaging techniques.<ref>{{cite journal | last1 = Zatorre | first1 = R.J. | last2 = Perry | first2 = D.W. | last3 = Beckett | first3 = C.A. | last4 = Westbury | first4 = C.F. | last5 = Evans | first5 = A.C. | year = 1998 | title = Functional anatomy of musical processing in listeners with perfect pitch and relative pitch | url = | journal = Neurobiology | volume = 95 | issue = | pages = 3172–3177 }}</ref>  Positron emission tomography (PET) was utilized to measure cerebral blood flow (CBF) in musicians possessing AP and musicians lacking AP.  When presented with musical tones, similar patterns of increased CBF in auditory cortical areas emerged in both groups.  AP possessors and non-AP subjects demonstrated similar patterns of left dorsolateral frontal activity when they performed relative pitch judgments.  However, in non-AP subjects activation in the right inferior frontal cortex was present whereas AP possessors showed no such activity.  This finding suggests that musicians with AP do not need access to working memory devices for such tasks.  These findings imply that there is no specific regional activation pattern unique to AP.  Rather, the availability of specific processing mechanisms and task demands determine the recruited neural areas.

== Emotion ==
[[Emotion]]s induced by music activate similar frontal brain regions compared to emotions elicited by other stimuli.<ref name="ReferenceA"/> Schmidt and Trainor (2001) discovered that valence (i.e. positive vs. negative) of musical segments was distinguished by patterns of frontal EEG activity.<ref name="Schmidt">{{cite journal | last1 = Schmidt | first1 = L.A. | last2 = Trainor | first2 = L.J. | year = 2001 | title = Frontal brain electrical activity (EEG) distinguishes valence and intensity of musical emotions | url = | journal = Cognition and Emotion | volume = 15 | issue = 4| pages = 487–500 }}</ref>  Joyful and happy musical segments were associated with increases in left frontal EEG activity whereas fearful and sad musical segments were associated with increases in right frontal EEG activity.  Additionally, the intensity of emotions was differentiated by the pattern of overall frontal EEG activity.  Overall frontal region activity increased as affective musical stimuli became more intense.<ref name="Schmidt"/>

Music is able to create an incredibly pleasurable experience that can be described as "chills".<ref name="Blood">{{cite journal | doi = 10.1073/pnas.191355898 | last1 = Blood | first1 = A. J. | last2 = Zatorre | first2 = R. J. | year = 2001 | title = Intensely pleasurable responses to music correlate with activity in brain regions implicated in reward and emotion | url = | journal = Proceedings of the National Academy of Sciences of the United States of America | volume = 98 | issue = 20| pages = 11818–11823 | pmid = 11573015 | pmc = 58814 }}</ref> Blood and Zatorre (2001) used PET to measure changes in cerebral blood flow while participants listened to music that they knew to give them the "chills" or any sort of intensely pleasant emotional response. They found that as these chills increase, many changes in cerebral blood flow are seen in brain regions such as the [[amygdala]], [[orbitofrontal cortex]], [[ventral striatum]], [[midbrain]], and the ventral medial [[prefrontal cortex]]. Many of these areas appear to be linked to reward, motivation, emotion, and arousal, and are also activated in other pleasurable situations.<ref name="Blood"/> [[Nucleus accumbens#Research|Nucleus accumbens]] (a part of [[striatum]]) is involved in both music related emotions, as well as rhythmic timing.

When unpleasant melodies are played, the posterior [[cingulate cortex]] activates, which indicates a sense of conflict or emotional pain.<ref name="Tramo"/> The right hemisphere has also been found to be correlated with emotion, which can also activate areas in the cingulate in times of emotional pain, specifically social rejection (Eisenberger). This evidence, along with observations, has led many musical theorists, philosophers and neuroscientists to link emotion with tonality. This seems almost obvious because the tones in music ''seem'' like a characterization of the tones in human speech, which indicate emotional content. The [[vowels]] in the [[phonemes]] of a song are elongated for a dramatic effect, and it seems as though musical tones are simply exaggerations of the normal verbal tonality.

== Memory ==

=== Neuropsychology of musical memory ===

[[Music-related memory|Musical memory]] involves both explicit and implicit memory systems.<ref>{{cite journal | doi = 10.1007/s11065-009-9085-2 | last1 = Baird | first1 = A. | last2 = Samson | first2 = S. | year = 2009 | title = Memory for music in Alzheimer's Disease: Unforgettable?. | url = | journal = Neuropsychological Review | volume = 19 | issue = | pages = 85–101 }}</ref> Explicit musical memory is further differentiated between episodic (where, when and what of the musical experience) and semantic (memory for music knowledge including facts and emotional concepts). Implicit memory centers on the 'how' of music and involves automatic processes such as procedural memory and motor skill learning – in other words skills critical for playing an instrument. Samson and Baird (2009) found that the ability of musicians with Alzheimer's Disease to play an instrument (implicit procedural memory) may be preserved.

=== Neural correlates of musical memory ===

A PET study looking into the neural correlates of musical semantic and episodic memory found distinct activation patterns.<ref name="Platel">{{cite journal | doi = 10.1016/S1053-8119(03)00287-8 | last1 = Platel | first1 = H. | last2 = Baron | first2 = J-C. | last3 = Desgranges | first3 = B. | last4 = Bernard | first4 = F. | last5 = Eustache | first5 = F. | year = 2003 | title = Semantic and episodic memory of music are subserved by distinct neural networks | url = | journal = NeuroImage | volume = 20 | issue = 1| pages = 244–256 | pmid = 14527585 }}</ref> Semantic musical memory involves the sense of familiarity of songs. The semantic memory for music condition resulted in bilateral activation in the medial and orbital frontal cortex, as well as activation in the left angular gyrus and the left anterior region of the middle temporal gyri. These patterns support the functional asymmetry favouring the left hemisphere for semantic memory. Left anterior temporal and inferior frontal regions that were activated in the musical semantic memory task produced activation peaks specifically during the presentation of musical material, suggestion that these regions are somewhat functionally specialized for musical semantic representations. 

Episodic memory of musical information involves the ability to recall the former context associated with a musical excerpt.<ref name="Platel"/> In the condition invoking episodic memory for music, activations were found bilaterally in the middle and superior frontal gyri and precuneus, with activation predominant in the right hemisphere. Other studies have found the precuneus to become activated in successful episodic recall.<ref>{{cite journal | doi = 10.1097/00001756-199510020-00014 | last1 = Kapur | first1 = S. | last2 = Craik | first2 = F. I. M. | last3 = Jones | first3 = C. | last4 = Brown | first4 = G. M. | last5 = Houle | first5 = S. | last6 = Tulving | first6 = E. | year = 1995 | title = Functional role of the prefrontal cortex in retrieval of memories: A PET study | url = | journal = NeuroReport | volume = 6 | issue = 14| pages = 1880–1884 | pmid = 8547589 }}</ref> As it was activated in the familiar memory condition of episodic memory, this activation may be explained by the successful recall of the melody.

When it comes to memory for pitch, there appears to be a dynamic and distributed brain network subserves pitch memory processes. Gaab, Gaser, Zaehle, Jancke and Schlaug (2003) examined the functional anatomy of pitch memory using functional magnetic resonance imaging (fMRI).<ref>{{cite journal | doi = 10.1016/S1053-8119(03)00224-6 | last1 = Gaab | first1 = N | last2 = Gaser | first2 = C. | last3 = Zaehle | first3 = T. | last4 = Jancke | first4 = L. | last5 = Schlaug | first5 = G. | year = 2003 | title = Functional anatomy of pitch memory – and fMRI study with sparse temporal sampling | url = | journal = Neuroimage | volume = 19 | issue = 4| pages = 1417–1426 | pmid = 12948699 }}</ref>  An analysis of performance scores in a pitch memory task resulted in a significant correlation between good task performance and the supramarginal gyrus (SMG) as well as the dorsolateral cerebellum.  Findings indicate that the dorsolateral cerebellum may act as a pitch discrimination processor and the SMG may act as a short-term pitch information storage site.  The left hemisphere was found to be more prominent in the pitch memory task than the right hemispheric regions.

=== Therapeutic effects of music on memory ===
Musical training has been shown to aid [[memory]].  Altenmuller et al. studied the difference between active and passive musical instruction and found both that over a longer (but not short) period of time, the actively taught students retained much more information than the passively taught students. The actively taught students were also found to have greater cerebral cortex activation. It should also be noted that the passively taught students weren't wasting their time; they, along with the active group, displayed greater left hemisphere activity, which is typical in trained musicians.<ref name="Strickland"/>

==Development==
The musical four year olds have been found to have compared to one greater left hemisphere intrahemispheric coherence.<ref name="Strickland">{{cite journal | last1 = Strickland | first1 = JS. | author-separator =, | author-name-separator= | year = 2001 | title = Music and the Brain in Childhood Development | url =http://findarticles.com/p/articles/mi_qa3614/is_200101/ai_n8950759/ | journal = Childhood Education | volume = 78 | issue = | pages = 100–3 }}</ref> Musicians have been found to have more developed anterior portions of the [[corpus callosum]] in a study by Cowell et al. in 1992.  This was confirmed by a study by Schlaug et al. in 1995 who found that classical musicians between the ages of 21 and 36 have significantly greater anterior corpora callosa than the non-musical control. Schlaug also found that there was a strong correlation of musical exposure before the age of seven, and a great increase in the size of the corpus callosum.<ref name="Strickland"/> These fibers join together the left and right hemispheres and indicate an increased relaying between both sides of the brain. This suggests the merging between the spatial- emotiono-tonal processing of the right brains and the linguistical processing of the left brain. This large relaying across many different areas of the brain might contribute to music's ability to aid in memory function.

== Impairment ==

=== Focal hand dystonia ===

Focal hand [[dystonia]] is a task-related movement disorder associated with occupational activities that require repetitive hand movements.<ref>{{cite journal | last1 = Chen | first1 = R. | last2 = Hallett | first2 = M. | year = 1998 | title = Focal dystonia and repetitive motion disorders | url = | journal = Occupational health and industrial medicine | volume = 39 | issue = 3| page = 122 }}</ref>  Focal hand dystonia is associated with abnormal processing in the premotor and primary sensorimotor cortices.  An fMRI study examined five guitarists with focal hand dystonia.<ref>{{cite journal | doi = 10.1006/nimg.2000.0615 | last1 = Pujol | first1 = J. | last2 = Roset-Llobet | first2 = J. | last3 = Rosines-Cubells | first3 = D. | last4 = Deus | first4 = J. | last5 = Narberhaus | first5 = B. | last6 = Valls-Sole | first6 = J. | last7 = Capdevila | first7 = A. | last8 = Pascual-Leone | first8 = A. | year = 2000 | title = Brain cortical activation during guitar-induced hand dystonia studied by functional MRI | url = | journal = Neuroimage | volume = 12 | issue = 3| pages = 257–267 | pmid = 10944408 }}</ref>  The study reproduced task-specific hand dystonia by having guitarists use a real guitar neck inside the scanner as well as performing a guitar exercise to trigger abnormal hand movement.  The dystonic guitarists showed significantly more activation of the contralateral primary sensorimotor cortex as well as a bilateral underactivation of premotor areas.  This activation pattern represents abnormal recruitment of the cortical areas involved in motor control.  Even in professional musicians, widespread bilateral cortical region involvement is necessary to produce complex hand movements such as [[Musical scale|scales]] and [[arpeggio]]s.  The abnormal shift from premotor to primary sensorimotor activation directly correlates with guitar-induced hand dystonia.

=== Music agnosia ===

Music [[agnosia]], an [[auditory agnosia]], is a syndrome of selective impairment in music recognition.<ref>{{cite journal | doi = 10.1076/jnmr.28.3.209.3108 | last1 = Dalla Bella | first1 = S. | last2 = Peretz | first2 = I. | year = 1999 | title = Music agnosias: Selective impairments of music recognition after brain damage | url = | journal = Journal of New Music Research | volume = 28 | issue = 3| pages = 209–216 }}</ref> Three cases of music agnosia are examined by Dalla Bella and Peretz (1999); C.N., G.L., and I.R.. All three of these patients suffered bilateral damage to the auditory cortex which resulted in musical difficulties while speech understanding remained intact. Their impairment is specific to the recognition of once familiar melodies. They are spared in recognizing environmental sounds and in recognizing lyrics. Peretz (1996) has studied C.N.'s music agnosia further and reports an initial impairment of pitch processing and spared temporal processing.<ref>{{cite journal | doi = 10.1162/jocn.1996.8.6.481 | last1 = Peretz | first1 = I. | year = 1996 | title = Can we lose memory for music? A case of music agnosia in a nonmusician | url = | journal = Journal of Cognitive Neuroscience | volume = 8 | issue = 6| pages = 481–496 }}</ref> C.N. later recovered in pitch processing abilities but remained impaired in tune recognition and familiarity judgments.

Musical agnosias  may be categorized based on the process which is impaired in the individual.<ref>{{cite journal | doi = 10.1093/brain/123.9.1926 | last1 = Ayotte | first1 = J. | last2 = Peretz | first2 = I. | last3 = Rousseau | first3 = I. | last4 = Bard | first4 = C. | last5 = Bojanowski | first5 = M. | year = 2000 | title = Patterns of music agnosia associated with middle cerebral artery infarcts | url = | journal = Brain | volume = 123 | issue = | pages = 1926–1938 | pmid = 10960056 }}</ref> Apperceptive music agnosia involves an impairment at the level of perceptual analysis involving an inability to encode musical information correctly. Associative music agnosia reflects an impaired representational system which disrupts music recognition. Many of the cases of music agnosia have resulted from surgery involving the middle cerebral artery. Patient studies have surmounted a large amount of evidence demonstrating that the left side of the brain is more suitable for holding long-term memory representations of music and that the right side is important for controlling access to these representations. Associative music agnosias tend to be produced by damage to the left hemisphere, while apperceptive music agnosia reflects damage the to right hemisphere.

=== Congenital amusia ===
Congenital [[amusia]], otherwise known as [[tone deafness]], is a term for lifelong musical problems which are not attributable to mental retardation, lack of exposure to music or deafness, or brain damage after birth.<ref>{{cite journal | doi = 10.1111/j.1467-8721.2008.00600.x | last1 = Peretz | first1 = I. | year = 2008 | title = Musical disorders | url = | journal = Current Directions in Psychological Science | volume = 17 | issue = 5| pages = 329–333 }}</ref> Amusic brains have been found in fMRI studies to have less white matter and thicker cortex than controls in the right inferior frontal cortex. These differences suggest abnormal neuronal development in the auditory cortex and inferior frontal gyrus, two areas which are important in musical-pitch processing.

Studies on those with [[amusia]] suggest different processes are involved in speech [[tonality]] and musical tonality. [[Congenital]] amusics lack the ability to distinguish between pitches and so are for example unmoved by dissonance and playing the wrong key on a piano. They also cannot be taught to remember a melody or to recite a song; however, they are still capable of hearing the intonation of speech, for example, distinguishing between "You speak French" and "You speak French?" when spoken.

=== Amygdala damage ===
[[File:Amgydala.jpg|right|200px|thumb|Damage to the [[amygdala]] may impair recognition of scary music.]]

Damage to the amygdala has selective emotional impairments on musical recognition.  Gosselin, Peretz, Johnsen and Adolphs (2007) studied S.M., a patient with bilateral damage of the [[amygdala]] with the rest of the temporal lobe undamaged and found that S.M. was impaired in recognition of scary and sad music.<ref>{{cite journal | doi = 10.1016/j.neuropsychologia.2006.07.012 | last1 = Gosselin | first1 = N. | last2 = Peretz | first2 = I. | last3 = Johnsen | first3 = E. | last4 = Adolphs | first4 = R. | year = 2007 | title = Amygdala damage impairs emotion recognition from music | url = | journal = Neuropsychologia | volume = 45 | issue = 2| pages = 236–244 | pmid = 16970965 }}</ref> S.M.'s perception of happy music was normal, as was her ability to use cues such as tempo to distinguish between happy and sad music. It appears that damage specific to the amygdala can selectively impair recognition of scary music.

=== Selective deficit in music reading ===

Specific musical impairments may result from brain damage leaving other musical abilities intact.  Cappelletti, Waley-Cohen, Butterworth and Kopelman (2000) studied a single case study of patient P.K.C., a professional musician who sustained damage to the left posterior temporal lobe as well as a small right occipitotemporal lesion.<ref>{{cite journal | doi = 10.1080/13554790008402780 | last1 = Cappelletti | first1 = M. | last2 = Waley-Cohen | first2 = H. | last3 = Butterworth | first3 = B. | last4 = Kopelman | first4 = M. | year = 2000 | title = A selection loss of the ability to read and write music | url = | journal = Neurocase | volume = 6 | issue = 4| pages = 321–332 }}</ref>  After sustaining damage to these regions, P.K.C. was selectively impaired in the areas of reading, writing and understanding musical notation but maintained other musical skills.  The ability to read aloud letters, words, numbers and symbols (including musical ones) was retained.  However, P.K.C. was unable to read aloud musical notes on the staff regardless of whether the task involved naming with the conventional letter or by singing or playing.  Yet despite this specific deficit, P.K.C. retained the ability to remember and play familiar and new melodies.

=== Auditory arrhythmia ===

Arrhythmia in the auditory modality is defined as a disturbance of rhythmic sense; and includes deficits such as the inability to rhythmically perform music, the inability to keep time to music and the inability to discriminate between or reproduce rhythmic patterns.<ref name="Wilson">{{cite journal | doi = 10.1016/S0028-3932(01)00198-1 | last1 = Wilson | first1 = S.J. | last2 = Pressing | first2 = J.L. | last3 = Wales | first3 = R.J. | year = 2002 | title = Modelling rhythmic function in a musician post-stroke | url = | journal = Neuropsychologia | volume = 40 | issue = 8| pages = 1494–1505 | pmid = 11931954 }}</ref>  A study investigating the elements of rhythmic function examined Patient H.J., who acquired arrhythmia after sustaining a right temporoparietal infarct.<ref name="Wilson"/>  Damage to this region impaired H.J.'s central timing system which is essentially the basis of his global rhythmic impairment.  H.J. was unable to generate steady pulses in a tapping task.  These findings suggest that keeping a musical beat relies on functioning in the right temporal auditory cortex.

==See also==

=== Related fields ===
*[[Cognitive musicology]]
*[[Music cognition]]
*[[Music psychology]]
*[[Music therapy]]
*[[Psychoacoustics]]

== References ==
{{Reflist|2}}

==Further reading==
* {{cite book | title = The neurosciences and music II : from perception to performance | publisher = New York Academy of Sciences | location = New York, N.Y | year = 2005 | isbn = 1-57331-610-5 }}

== External links ==
*[http://www.MusicCognition.info/ MusicCognition.info - A Resource and Information Center]
*{{cite journal|last=Croom|first=Adam M.|title=Music, Neuroscience, and the Psychology of Wellbeing: A Précis|journal=Frontiers in Theoretical and Philosophical Psychology|year=2012|month=January|volume=2|issue=393|pages=1–15|url=http://www.frontiersin.org/theoretical_and_philosophical_psychology/10.3389/fpsyg.2011.00393/abstract}}
*{{cite news|last=Deutsch|first=Diana|title=Speaking in Tones: Music and Language Partner in the Brain|url=http://www.scientificamerican.com/article.cfm?id=speaking-in-tones-jul10|newspaper=[[Scientific American Mind]]|date=July 29, 2010|authorlink=Diana Deutsch}}
*{{cite news|last=Weinberger|first=Norman M.|title=Music and the Brain|url=http://www.sciam.com/article.cfm?chanID=sa006&articleID=0007D716-71A1-1179-AF8683414B7F0000|newspaper=[[Scientific American]]|date=October 25, 2004}}
*[http://prod.informaworld.com/smpp/title~db=all~content=g911586331 Connection Science (2009). Special Issue "Music, Brain, & Cognition" 21(2-3).]

{{Music cognition}}

{{DEFAULTSORT:Cognitive Neuroscience Of Music}}
[[Category:Cognitive neuroscience]]
[[Category:Music cognition]]
[[Category:Musicology]]