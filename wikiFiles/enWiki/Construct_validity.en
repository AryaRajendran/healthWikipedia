There are three overarching forms of [[Validity (statistics)|validity]]: [[Content validity|content]], [[Criterion validity|criterion]], and '''construct validity'''.<ref>Brown, J. D. (1996). Testing in language programs. Upper Saddle River, NJ: Prentice Hall Regents. 231-249</ref> Construct validity refers to the validity of inferences that observations or measurement tools actually represent or measure the construct being investigated.<ref name="Polit">Polit DF Beck CT (2012). Nursing Research: Generating and Assessing Evidence for Nursing Practice, 9th ed. Philadelphia, USA: Wolters Klower Health, Lippincott Williams & Wilkins</ref> In lay terms, construct validity examines the question: Does the measure behave like the theory says a measure of that construct should behave?  Constructs are abstractions that are deliberately created by researchers in order to conceptualize the [[latent variable]], which is the cause of scores on a given measure (although it is not directly observable). Construct validity is essential to the perceived overall validity of the test. Construct validity is particularly important in the [[social sciences]], [[psychology]], [[psychometrics]] and language studies. In modern [[psychometrics]] the validity of a psychological test is interpreted within the frame of the construct validity.<ref>Schotte, C. K. W., Maes, M., Cluydts, R., De Doncker, D., & Cosyns, P. (1997). Construct validity of the Beck Depression Inventory in a depressive population. Journal of Affective Disorders, 46(2), 115-125.</ref> Psychologists such as [[Samuel Messick]] (1989) have pushed for a unified view of construct validity “…as an integrated evaluative judgment of the degree to which empirical evidence and theoretical rationales support the adequacy and appropriateness of inferences and actions based on test scores…”<ref>Messick, Samuel. "Test validity: A matter of consequence." Social Indicators Research 45.1-3 (1998): 35-44.</ref> Key to construct validity are the theoretical ideas behind the trait under consideration, i.e. the concepts that organize how aspects of [[personality]], [[intelligence]], etc. are viewed.<ref>Pennington, Donald (2003). Essential Personality. Arnold. p. 37. ISBN 0-340-76118-0.</ref> [[Paul Meehl]] states that "The best construct is the one around which we can build the greatest number of inferences, in the most direct fashion."<ref name="Cronbach">Cronbach, L., & Meehl, P. (1955). Construct validity in psychological tests..Psychol Bull, 52(4), 281-302.</ref>

== Definition ==
Construct validity refers to “the degree to which a test measures what it claims, or purports, to be measuring.” <ref> Brown, J. D. (1996). [ http://jalt.org/test/bro_8.htm “Testing in language programs.’] , Upper Saddle River, NJ: Prentice Hall Regents. Retrieved April 6th, 2013.</ref> In other words it occurs “whenever a test is to be interpreted as a measure of some attribute or quality which is not operationally defined.”<ref> Cronbach, L. J, Meehl, P.E. (1955). [http://psychclassics.yorku.ca/Cronbach/construct.htm “Construct Validity in Psychological Tests.”], Pschological Bulletin, 52, 281-302. Retrieved April 6, 2013.</ref>

==Convergent and Discriminant Validity==
{{Main| convergent validity| discriminant validity }}
Convergent and discriminant validity are the two subtypes of validity that make up construct validity. Convergent validity refers to the degree to which two measures of constructs that theoretically should be related, are in fact related. In contrast discriminant validity tests whether concepts or measurements that are supposed to be unrelated are, in fact, unrelated.<ref name="Campbell">Campbell, D. T. (1959). Convergent and discriminant validation by the multitrait-multimethod matrix. (56). Psychological Bulletin. pp. 81–105</ref> Take, for example, a construct of general happiness. If a measure of general happiness had convergent validity then constructs similar to happiness (satisfaction, contentment, cheerfulness, etc.) should relate closely to the measure of general happiness. If this measure has discriminate validity than constructs that are not supposed to be related to general happiness (sadness, depression, despair, etc.) should not relate to the measure of general happiness. Measures can have one of the subtypes of construct validity and not the other. Using the example of general happiness, a researcher could create an inventory where there is a very high correlation between general happiness and contentment, but if there is also a significant correlation between happiness and depression, then the measures construct validity is called into question. The test has convergent validity but not discriminate validity.

== History ==
Throughout the 1940’s scientists had been trying to come up with ways to validate experiments prior to publishing them. The result of this was a myriad of different validities ( [[Intrinsic validity]] , [[face validity]] , [[logical validity]] , [[empirical validity]] , etc…). This made it difficult to tell which ones were actually the same, which ones weren’t useful at all. Until the middle of the 1950’s there were very few universally accepted methods to validate psychological experiments. The main reason for this was because no one had figured out exactly which qualities of the experiments should be looked at before publishing. Between 1950 and 1954 the APA Committee on Psychological Tests met and discussed the issues surrounding the validation of psychological experiments.<ref name="Cronbach"/> 

Around this time the term construct validity was first coined by [[Paul Meehl]] and [[Lee Cronbach]] in their seminal article [[Construct Validity In Psychological Tests]]. They noted idea of construct validly was not new at that point. Rather, it was a combinations of many different  types of validity dealing with theoretical concepts. They proposed the following three steps to evaluate construct validity:
'''<br /> 1.) articulating a set of theoretical concepts and their interrelations<br /> 2.) developing ways to measure the hypothetical constructs proposed by the theory<br /> 3.) empirically testing the hypothesized relations<ref name="Cronbach"/> <br />'''

Many psychologist note that an important role of construct validation in [[psychometrics]] was that it place more emphasis on theory as opposed to validation. The core issue with validation was that a test could be validated, but that did not necessarily show that it measured the theoretical construct it purported to measure. 
Construct validity has three aspects or components: the substantive component, structural component, and external component.<ref name= "Loevinger">Loevinger, J. (1957). Objective Tests As Instruments Of Psychological Theory: Monograph Supplement 9. Psychological reports, 3(3), 635-694</ref> They are related close to three stages in the test construction process: constitution of the pool of items, analysis and selection of the internal structure of the pool of items, and correlation of test scores with criteria and other variables.

In the 1970s there was growing debate between theorist who began to see construct validity as the dominant model pushing towards a more unified theory of validity and those who continued to work from multiple validity frameworks.<ref>Kane, M. T. (2006). Validation. Educational measurement, 4, 17-64.</ref>  Many psychologist and education researchers saw “predictive, concurrent, and content validities as essentially ad hoc, construct validity was the whole of validity from a scientific point of view”<ref name="Loevinger"/> In the 1974 version The [[Standards for Educational and Psychological Testing]] the inter-relatedness of the three different aspects of validity was recognized: "These aspects of validity can be discussed independently, but only for convenience. They are interrelated operationally and logically; only rarely is one of them alone important in a particular situation"   In 1989 Messick presented a new conceptualization of construct validity as a unified and milt-faceted concept.<ref>Messick, S. (1989). Validity. In R. L. Linn (Ed.), Educational Measurement (3rd ed., pp. 13-103). New York: American Council on Education/Macmillan</ref> Under this framework, all forms of validity are connected to and are dependent on the quality of the construct. He noted that a unified theory was not his own idea, but rather the culmination of debate and discussion within the scientific community over the preceding decades. There are six aspects of construct validity in Messick’s Unified Theory of Construct Validity.<ref>Messick, S. (1995). Standards of validity and the validity of standards in performance assessment. Educational Measurement: Issues and Practice, 14(4), 5-8.</ref> They examine six items that measure the quality of a test’s construct validity:

<br /> 1.)'''Consequential'''- What are the potential risks if the scores are, in actuality, invalid or inappropriately interpreted? Is the test still worthwhile given the risks?<br />2.)'''Content'''- Do test items appear to be measuring the construct of interest?<br />3.)'''Substantive'''- Is the theoretical foundation underlying the construct of interest sound?<br />4.)'''Structural'''- Do the interrelationships of dimensions measured by the test correlate with the construct of interest and test scores?<br />5.)'''External'''- Does the test have convergent, discriminant, and predictive qualities?<br />6.)'''Generalizability'''- Does the test generalize across different groups, settings and tasks?

How construct validity should be properly viewed is still a subject of debate for validity theorists. The core of the difference lies in an [[epistemology|epistemological]] difference between [[Positivist]] and [[Postpositivist]] theorists.

== Evaluation ==
Evaluation of construct validity requires that the correlations of the measure be examined in regard to variables that are known to be related to the construct (purportedly measured by the instrument being evaluated or for which there are theoretical grounds for expecting it to be related). This is consistent with the [[multitrait-multimethod matrix]] (MTMM) of examining construct validity described in Campbell and Fiske's landmark paper (1959).<ref name="Campbell"/> There are other method to evaluate construct validity besides MTMM. It can be evaluated through different forms of [[factor analysis]], [[structural equation modeling]] (SEM), and other statistical evaluations.<ref>Hammond, K. R., Hamm, R. M., & Grassia, J. (1986). Generalizing over conditions by combining the multitrait multimethod matrix and the representative design of experiments (No. CRJP-255A). COLORADO UNIV AT BOULDER CENTER FOR RESEARCH ON JUDGMENT AND POLICY.</ref><ref>Westen, Drew, and Robert Rosenthal. 2003. Quantifying construct validity: Two simple measures. Journal of Personality and Social Psychology 84, no. 3: 608-618.</ref> It is important to note single study does not prove construct validity. Rather it is a continuous process of evaluation, reevaluation, refinement, and development. Correlations that fit the expected pattern contribute evidence of construct validity. Construct validity is a judgment based on the accumulation of correlations from numerous studies using the instrument being evaluated.<ref>Peter, J. P. (1981). Construct validity: a review of basic issues and marketing practices. Journal of Marketing Research, 133-145.</ref>

Most researchers attempt to test the construct validity before the main research. To do this [[pilot studies]] may be utilized. Pilot studies are small scale preliminary studies aimed at testing the feasibility of a full-scale test. These pilot studies establish the strength of their research and allow them to make any necessary adjustments. Another method is the known-groups technique, which involves administering the measurement instrument to groups expected to differ due to known characteristics. Hypothesized relationship testing involves logical analysis based on theory or prior research.<ref name="Polit"/>[[Intervention studies]] are yet another method of evaluating construct validity. Intervention studies where a group with low scores in the construct is tested, taught the construct, and then re-measured can demonstrate a tests construct validity. If there is a significant difference pre-test and post-test, which are analyzed by statistical tests, then this may demonstrate good construct validity.<ref>Dimitrov, D. M., & Rumrill, Jr, P. D. (2003). Pretest-posttest designs and measurement of change. Work: A Journal of Prevention, Assessment and Rehabilitation, 20(2), 159-165.</ref>

=== Nomological Network ===
{{Main|nomological network}}
[[Paul Meehl]] and [[Lee Cronbach]] (1957) proposed that the development of a nomological net was essential to measurement of a tests construct validity.  A [[nomological network]] defines a construct by illustrating its relation to other constructs and behaviors.<ref name="Cronbach"/> It is a representation of the concepts (constructs) of interest in a study, their observable manifestations and the interrelationship among them. It examines whether the relationships between similar construct are considered with relationships between the observed measures of the constructs. Thorough observation of constructs relationships to each other it can generate new constructs. For example, [[intelligence]] and [[working memory]] are considered highly related constructs. Through the observation of their underlying components psychologists developed new theoretical constructs such as: controlled attention<ref>Engle, R. W., Kane, M. J., & Tuholski, S. W. (1999). Individual differences in working memory capacity and what they tell us about controlled attention, general fluid intelligence, and functions of the prefrontal cortex. In A. Miyake, & P. Shah (Eds.),Models of working memory (pp. 102−134). Cambridge: Cambridge University Press.</ref> and short term loading.<ref>Ackerman, P. L., Beier, M. E., & Boyle, M. O. (2002). Individual differences in working memory within a nomological network of cognitive and perceptual speed abilities. Journal of Experimental Psychology-General, 131, 567−589.</ref> Creating a nomological net can also make the observation and measurement of existing constructs more efficient by pinpointing errors.<ref name="Cronbach"/> Researchers have found that studying the dimensions of the human skull ([[Phrenology]]) are not indicators of intelligence. By removing the theory of Phernology from the nomological net of intelligence, testing constructs of intelligence is made more efficient. The weaving of all of these interrelated concepts and their observable traits creates a “net” that supports their theoretical concept. For example, in the nomological network for academic achievement, we would expect observable traits of academic achievement (i.e. GPA, SAT, and ACT scores) to relate to the observable traits for studiousness (hours spent studying, attentiveness in class, detail of notes). If they do not then there is a problem with the measurement of [[academic achievement]] or studiousness. If they are indicators of one another then the nomological network, and therefore the constructed theory, of academic achievement is strengthened. Although the nomological network proposed a theory of how to strengthen constructs, it doesn't tell us how we can assess the construct validity in a study.

=== Multitrait-Multimethod Matrix ===
{{Main|Multitrait-Multimethod Matrix}}
The [[multitrait-multimethod matrix]] (MTMM) is an approach to examining Construct Validity developed by Campbell and Fiske (1959).<ref name="Campbell"/> This model examines convergence (evidence that different measurement methods of a construct give similar results) and discriminability (ability to differentiate the construct from other related constructs). It measures six traits: the evaluation of convergent validity, the evaluation of discriminant (divergent) validity, trait-method units, multitrait-multimethods, truly different methodologies, and trait characteristics. This design allows investigators to test for: “convergence across different measures…of the same ‘thing’…and for divergence between measures…of related but conceptually distinct ‘things'.<ref>Cook, T. D., & Campbell, D. T. (1979). Quasi-experimentation. Boston: Houghton Mifflin. Edgington, E. S. (1974). A new tabulation of statistical procedures used in APA journals. American Psychologist, 29, 61</ref>

==Construct Validity in Experiments==

In order to show an example of construct validity, it would be best to do so with a landmark experiment.  One of which is the Milgram’s study of obedience.  The purpose of this study was to look at whether or not a person would continue to do something they were uncomfortable with just because someone of authority was telling them to do so.  Essentially it was intended to test whether people are obedient or not.

This was done by getting participants through voluntary participation in the form of a newspaper advertisement<ref name="Conflict"> Ksenyeh, Ed & Liu, David. (2001).  Conflict, Order and Action : Readings in Sociology. p. 134 - 149. ISBN  155130192X, 9781551301921. </ref>.  They were all men of various ages, level of education, and occupation.  There was also and “experimenter” running the experiment and “learner” that acted in the study<ref name="Conflict" />. The participants were essentially to listen to the “experimenter” and shock the “learner” every time they responded incorrectly to studied information.  There were 30 different levels of shock to be administered<ref name="Conflict" />.   The participants were allowed to hear the “learner’s” reaction to the shock.  If the participant did not want to continue with the shocks they were heavily encouraged to continue.  If they refused they were considered defiant before the 13th step and if they continued passed the 13th step they were considered obedient<ref name="Conflict" />.

Now look at this in regard to construct validity.  Does the level at which the person decides not to continue with the shock really accurately measure a person’s level of obedience?  There are two ways looking at this idea. There is the definitionalist’s view of construct validity.  This view states it is essential to define exactly what we want to be looking for when we are testing something <ref name="Research Methods">
Trochim, William. The Research Methods Knowledge Base, 2nd Edition. Internet WWW page, at URL: [http://www.socialresearchmethods.net/kb/consthre.php ].</ref>   So in this case, is the level of shock testing for level of obedience and level of obedience only?  The other view is called the relationist’s view.  This view states that, in this case, it would be important to make sure to test for obedience since that is the intention of the study, but if other factors come into play as long as it can relate to obedience it is fine that it may be included in the testing <ref name="Research Methods" />.

It would be said that the Milgram’s study does measure obedience very effectively, but it can be seen where other factors may come into play.  So this study does seem to have construct validity.  However it is important to note that this most likely aligns the relationist’s view.  This is because this experiment can also just be showing that some people are just oblivious to things going on around them.  They could also feel a sense of responsibility to finish as they were monetarily compensated for their time.  They were guaranteed the money no matter what but some people may have really taken that to heart  <ref name="Conflict" />.

The level does measure level of obedience within the relationist’s view.  Construct validity is present in the Milgram’s study making it a good valid study for its testing purposes at the time it was administered.  In this day and age though, it would not be approved by an internal review board due to the possible psychological harm done to the participant. Even still, this is a landmark study and one that contains a good example to proper construct validity.

==Threats to Construct Validity==
Since construct validity attempts to create a universal cohesion, there are many possible threats to it. Construct validity is threatened by participant re-activity to the study situation (eg the [[Hawthorne effect]]), altered behavior due to the novelty of a new treatment, researcher expectations, and diffusion or contamination of the treatment conditions. Developing a poor construct can be an issue. If a construct is too broad or too narrow it can invalidate an entire experiment.<ref>MacKenzie, S. B. (2003). The dangers of poor construct conceptualization. Journal of the Academy of Marketing Science, 31(3), 323-326.</ref> For example, a researcher might try to use job satisfaction to define overall happiness. This is too narrow, as somebody may love their job but have an unhappy life outside the workplace. Likewise, using general happiness to measure happiness at work is too broad. Construct confounding is another threat. Construct confounding occurs when other constructs effect the measured construct.<ref>White, D., & Hultquist, R. A. (1965). Construction of confounding plans for mixed factorial designs. The Annals of Mathematical Statistics, 1256-1271.</ref> For example, self-worth is confounded by self-esteem and self-confidence. One’s perception of self-worth is effected by their state of self-esteem or self-confidence. Another threat is [[hypothesis guessing]]. If a subject makes assumption of the aims of the research their behavior changes and it effects construct validity. Similar, if an individual becomes apprehensive during an experiment, it could affect his or her performance.<ref>McCroskey, J. C., Richmond, V. P., & McCroskey, L. L. (2006). An introduction to communication in the classroom: The role of communication in teaching and training. Boston: Allyn & Bacon</ref> Researches themselves, can be threats to construct validity. Researcher’s expediencies and biases, whether overt or unintentional, can lower construct validity by clouding the effect of the research variable. To avoid these effects interaction should be minimized and [[double-blind experiments]] should be used. Variance in scores can show weak construct validity. For example if native English speakers score higher than individuals who speak English a second language on a test written in English trying to measure intelligence, than the test has poor construct validity. It measures language ability rather than intelligence.

Another take on construct validity is described by William M. Trochim <ref name="Trochim, William M.">[http://www.socialresearchmethods.net/kb/consthre.php],Trochim, William M. The Research Methods Knowledge Base, 2nd Edition.</ref>. He includes “Inadequate Preoperational Explication of Constructs, Mono-Operation Bias, Mono-Method Bias, Interaction of Different Treatments, Interaction of Testing and Treatment, Restricted Generalizability Across Constructs, Confounding Constructs and Levels of Constructs, Hypothesis Guessing, Evaluation Apprehension, and Experimenter Expectancies", in his definitions of threats to construct validity <ref name="Trochim, William M." />.

=== Inadequate Preoperational Explications of Constructs ===
"Inadequate preoperational explications of constructs" is not defining the construct of the experiment well enough <ref name="Trochim, William M." />.

=== Mono-Operation Bias ===
"Mono-operation bias" pertains to only using one variable or only suggesting one way of dealing with a problem <ref name="Trochim, William M." />.The problem with this is, it does not look at different aspects of the experiment and the true reasons for the experiment <ref name="Trochim, William M." />.

=== Mono-Method Bias ===
"Mono-method bias" is how an experimenter measured or observed their experiment may correlate to things they did not expect <ref name="Trochim, William M." />.

=== Interaction of Different Treatments ===
"Interaction of different treatments" deals with an experiment where an experimenter may implement a plan to help a certain population, and they assume that their plan caused an effect that could not be achieved for other reasons that might also be incorporated with that population <ref name="Trochim, William M." />.

=== Interaction of Testing and Treatment ===
"Interaction of testing and treatment" involves labeling a program without addressing the issue of the treatment being a possible part of the program <ref name="Trochim, William M." />.

=== Restricted Generalizability Across Constructs ===
"Restricted generalizability across constructs" means an experiment worked in one particular situation, but it might not work in any other situation than than that one <ref name="Trochim, William M." />.

=== Hypothesis Guessing ===
In "hypothesis guessing" the participants in a experiment may try to figure out what the goal of an experiment is, and their thoughts about what they think is being studied may affect how they respond in the experiment and alter the results. <ref name="Trochim, William M." />.

=== Evaluation Apprehension ===
"Evaluation apprehension" explains how a participant’s mind and body’s react to knowing that they are being experimented on . This could alter your results of an experiment <ref name="Trochim, William M." />.

=== Experimenter Expectancies ===
"Experimenter expectancies" explain that the way a researcher may want or may expect an experiment to go, may be a potential effect of why that experiment went a certain way <ref name="Trochim, William M." />.

== See Also ==
*[[Statistical conclusion validity]]
*[[Internal Validity]]
*[[Ecological Validity]]
*[[Content Validity]]
*[[External Validity]]
*[[Reliability (psychometrics)]]
*[[Face validity]]
*[[Logical validity]]

== References ==
{{Reflist}}

== External links ==
* [http://art.unt.edu/designresearchcenter/sites/default/files/articles/research_v2_ryan_gupta_hermosillo.pdf/ Useful reference guide for research terms]
* [http://www.socialresearchmethods.net/kb/nomonet.php/ Provides a visual representation of the nomological network]
* [http://www.mcps.umn.edu/assets/pdf/1_7_Cronbach.pdf/ Construct Validity in Psychological Tests pdf]

{{Uncategorized|date=April 2013}}